[
	{
		"label": "os",
		"kind": 6,
		"isExtraImport": true,
		"importPath": "os",
		"description": "os",
		"detail": "os",
		"documentation": {}
	},
	{
		"label": "StrOutputParser",
		"importPath": "langchain.schema",
		"description": "langchain.schema",
		"isExtraImport": true,
		"detail": "langchain.schema",
		"documentation": {}
	},
	{
		"label": "StrOutputParser",
		"importPath": "langchain.schema",
		"description": "langchain.schema",
		"isExtraImport": true,
		"detail": "langchain.schema",
		"documentation": {}
	},
	{
		"label": "StrOutputParser",
		"importPath": "langchain.schema",
		"description": "langchain.schema",
		"isExtraImport": true,
		"detail": "langchain.schema",
		"documentation": {}
	},
	{
		"label": "tqdm",
		"importPath": "tqdm",
		"description": "tqdm",
		"isExtraImport": true,
		"detail": "tqdm",
		"documentation": {}
	},
	{
		"label": "tqdm",
		"importPath": "tqdm",
		"description": "tqdm",
		"isExtraImport": true,
		"detail": "tqdm",
		"documentation": {}
	},
	{
		"label": "tqdm",
		"importPath": "tqdm",
		"description": "tqdm",
		"isExtraImport": true,
		"detail": "tqdm",
		"documentation": {}
	},
	{
		"label": "PromptTemplate",
		"importPath": "langchain.prompts",
		"description": "langchain.prompts",
		"isExtraImport": true,
		"detail": "langchain.prompts",
		"documentation": {}
	},
	{
		"label": "PromptTemplate",
		"importPath": "langchain.prompts",
		"description": "langchain.prompts",
		"isExtraImport": true,
		"detail": "langchain.prompts",
		"documentation": {}
	},
	{
		"label": "OpenAI",
		"importPath": "langchain_openai",
		"description": "langchain_openai",
		"isExtraImport": true,
		"detail": "langchain_openai",
		"documentation": {}
	},
	{
		"label": "OpenAI",
		"importPath": "langchain_openai",
		"description": "langchain_openai",
		"isExtraImport": true,
		"detail": "langchain_openai",
		"documentation": {}
	},
	{
		"label": "set_environment",
		"importPath": "config",
		"description": "config",
		"isExtraImport": true,
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "set_environment",
		"importPath": "config",
		"description": "config",
		"isExtraImport": true,
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "set_environment",
		"importPath": "config",
		"description": "config",
		"isExtraImport": true,
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "PromptTemplate",
		"importPath": "langchain",
		"description": "langchain",
		"isExtraImport": true,
		"detail": "langchain",
		"documentation": {}
	},
	{
		"label": "OpenAI",
		"importPath": "langchain",
		"description": "langchain",
		"isExtraImport": true,
		"detail": "langchain",
		"documentation": {}
	},
	{
		"label": "set_environment",
		"kind": 2,
		"importPath": "books.config",
		"description": "books.config",
		"peekOfCode": "def set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "books.config",
		"documentation": {}
	},
	{
		"label": "OPENAI_API_KEY",
		"kind": 5,
		"importPath": "books.config",
		"description": "books.config",
		"peekOfCode": "OPENAI_API_KEY = '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'\nHUGGINGFACEHUB_API_TOKEN = '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'\nREPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "books.config",
		"documentation": {}
	},
	{
		"label": "HUGGINGFACEHUB_API_TOKEN",
		"kind": 5,
		"importPath": "books.config",
		"description": "books.config",
		"peekOfCode": "HUGGINGFACEHUB_API_TOKEN = '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'\nREPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "books.config",
		"documentation": {}
	},
	{
		"label": "REPLICATE_API_TOKEN",
		"kind": 5,
		"importPath": "books.config",
		"description": "books.config",
		"peekOfCode": "REPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "books.config",
		"documentation": {}
	},
	{
		"label": "file_path",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "file_path = 'llm_input.txt'\n# Read the content of the file\nwith open(file_path, 'r', encoding='utf-8') as file:\n    content = file.read()\n# Split the content into paragraphs based on the newline character\nparagraphs = content.split('\\\\x')\n# Remove empty paragraphs\nparagraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "paragraphs",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "paragraphs = content.split('\\\\x')\n# Remove empty paragraphs\nparagraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup\n# \"\"\"Condense/optimize each paragraph (separated by \"\\x\")  by:\n# - Removing inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions, and adverbs\n# - Enclosing variable names, class names, nouns in backticks (``)\n# - Removing \"\\x\" in output\n# Here is the input:\"\"\"",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "paragraphs",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "paragraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup\n# \"\"\"Condense/optimize each paragraph (separated by \"\\x\")  by:\n# - Removing inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions, and adverbs\n# - Enclosing variable names, class names, nouns in backticks (``)\n# - Removing \"\\x\" in output\n# Here is the input:\"\"\"\nllm = OpenAI(model='gpt-3.5-turbo-instruct')\nuse_in_post = True",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "llm",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "llm = OpenAI(model='gpt-3.5-turbo-instruct')\nuse_in_post = True\nprompt_add_use_in_post = ' (separated by \"\\\\x\") ' if use_in_post else ' '\ntemplate = f\"\"\"Condense/optimize each paragraph{prompt_add_use_in_post}by:\n- Removing inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions, and adverbs\n- Enclosing names like variable, class, function in backticks (``)\n- Removing \"\\\\x\" in output\nHere is the input:\n\"\"\" + \"{text}\"\nprompt_template = PromptTemplate.from_template(template)",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "use_in_post",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "use_in_post = True\nprompt_add_use_in_post = ' (separated by \"\\\\x\") ' if use_in_post else ' '\ntemplate = f\"\"\"Condense/optimize each paragraph{prompt_add_use_in_post}by:\n- Removing inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions, and adverbs\n- Enclosing names like variable, class, function in backticks (``)\n- Removing \"\\\\x\" in output\nHere is the input:\n\"\"\" + \"{text}\"\nprompt_template = PromptTemplate.from_template(template)\noutput_parser = StrOutputParser()",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "prompt_add_use_in_post",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "prompt_add_use_in_post = ' (separated by \"\\\\x\") ' if use_in_post else ' '\ntemplate = f\"\"\"Condense/optimize each paragraph{prompt_add_use_in_post}by:\n- Removing inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions, and adverbs\n- Enclosing names like variable, class, function in backticks (``)\n- Removing \"\\\\x\" in output\nHere is the input:\n\"\"\" + \"{text}\"\nprompt_template = PromptTemplate.from_template(template)\noutput_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "template",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "template = f\"\"\"Condense/optimize each paragraph{prompt_add_use_in_post}by:\n- Removing inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions, and adverbs\n- Enclosing names like variable, class, function in backticks (``)\n- Removing \"\\\\x\" in output\nHere is the input:\n\"\"\" + \"{text}\"\nprompt_template = PromptTemplate.from_template(template)\noutput_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "prompt_template",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "prompt_template = PromptTemplate.from_template(template)\noutput_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI\n    runnable = prompt_template | llm | output_parser",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "output_parser",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "output_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI\n    runnable = prompt_template | llm | output_parser\n    summary = runnable.invoke({'text': paragraph})",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "summaries",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "summaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI\n    runnable = prompt_template | llm | output_parser\n    summary = runnable.invoke({'text': paragraph})\n    # Append the summary to the list\n    summaries.append(summary)",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "output_file_path",
		"kind": 5,
		"importPath": "books.gpt_book",
		"description": "books.gpt_book",
		"peekOfCode": "output_file_path = 'llm_output.txt'\nwith open(output_file_path, 'a', encoding='utf-8') as output_file:\n    for summary in tqdm(summaries):\n        output_file.write(summary + '\\n')\nprint(f'Summaries appended to {output_file_path}')",
		"detail": "books.gpt_book",
		"documentation": {}
	},
	{
		"label": "file_path",
		"kind": 5,
		"importPath": "books.gpt_post",
		"description": "books.gpt_post",
		"peekOfCode": "file_path = 'llm_input.txt'\n# Read the content of the file\nwith open(file_path, 'r', encoding='utf-8') as file:\n    content = file.read()\n# Split the content into paragraphs based on the newline character\nparagraphs = content.split('\\\\x')\n# Remove empty paragraphs\nparagraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup",
		"detail": "books.gpt_post",
		"documentation": {}
	},
	{
		"label": "paragraphs",
		"kind": 5,
		"importPath": "books.gpt_post",
		"description": "books.gpt_post",
		"peekOfCode": "paragraphs = content.split('\\\\x')\n# Remove empty paragraphs\nparagraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup\nllm = OpenAI(model='gpt-3.5-turbo-instruct')\nprompt_template = PromptTemplate.from_template(\"Condense content:\\n{text}\")\noutput_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []",
		"detail": "books.gpt_post",
		"documentation": {}
	},
	{
		"label": "paragraphs",
		"kind": 5,
		"importPath": "books.gpt_post",
		"description": "books.gpt_post",
		"peekOfCode": "paragraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup\nllm = OpenAI(model='gpt-3.5-turbo-instruct')\nprompt_template = PromptTemplate.from_template(\"Condense content:\\n{text}\")\noutput_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs",
		"detail": "books.gpt_post",
		"documentation": {}
	},
	{
		"label": "llm",
		"kind": 5,
		"importPath": "books.gpt_post",
		"description": "books.gpt_post",
		"peekOfCode": "llm = OpenAI(model='gpt-3.5-turbo-instruct')\nprompt_template = PromptTemplate.from_template(\"Condense content:\\n{text}\")\noutput_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI",
		"detail": "books.gpt_post",
		"documentation": {}
	},
	{
		"label": "prompt_template",
		"kind": 5,
		"importPath": "books.gpt_post",
		"description": "books.gpt_post",
		"peekOfCode": "prompt_template = PromptTemplate.from_template(\"Condense content:\\n{text}\")\noutput_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI\n    runnable = prompt_template | llm | output_parser",
		"detail": "books.gpt_post",
		"documentation": {}
	},
	{
		"label": "output_parser",
		"kind": 5,
		"importPath": "books.gpt_post",
		"description": "books.gpt_post",
		"peekOfCode": "output_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI\n    runnable = prompt_template | llm | output_parser\n    summary = runnable.invoke({'text': paragraph})",
		"detail": "books.gpt_post",
		"documentation": {}
	},
	{
		"label": "summaries",
		"kind": 5,
		"importPath": "books.gpt_post",
		"description": "books.gpt_post",
		"peekOfCode": "summaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI\n    runnable = prompt_template | llm | output_parser\n    summary = runnable.invoke({'text': paragraph})\n    # Append the summary to the list\n    summaries.append(summary)",
		"detail": "books.gpt_post",
		"documentation": {}
	},
	{
		"label": "output_file_path",
		"kind": 5,
		"importPath": "books.gpt_post",
		"description": "books.gpt_post",
		"peekOfCode": "output_file_path = 'llm_output.txt'\nwith open(output_file_path, 'a', encoding='utf-8') as output_file:\n    for summary in tqdm(summaries):\n        output_file.write(summary + '\\n')\nprint(f'Summaries appended to {output_file_path}')",
		"detail": "books.gpt_post",
		"documentation": {}
	},
	{
		"label": "set_environment",
		"kind": 2,
		"importPath": "posts.config",
		"description": "posts.config",
		"peekOfCode": "def set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "posts.config",
		"documentation": {}
	},
	{
		"label": "OPENAI_API_KEY",
		"kind": 5,
		"importPath": "posts.config",
		"description": "posts.config",
		"peekOfCode": "OPENAI_API_KEY = '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'\nHUGGINGFACEHUB_API_TOKEN = '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'\nREPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "posts.config",
		"documentation": {}
	},
	{
		"label": "HUGGINGFACEHUB_API_TOKEN",
		"kind": 5,
		"importPath": "posts.config",
		"description": "posts.config",
		"peekOfCode": "HUGGINGFACEHUB_API_TOKEN = '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'\nREPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "posts.config",
		"documentation": {}
	},
	{
		"label": "REPLICATE_API_TOKEN",
		"kind": 5,
		"importPath": "posts.config",
		"description": "posts.config",
		"peekOfCode": "REPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "posts.config",
		"documentation": {}
	},
	{
		"label": "file_path",
		"kind": 5,
		"importPath": "posts.gpt_post",
		"description": "posts.gpt_post",
		"peekOfCode": "file_path = 'crawled_text.txt'\n# Read the content of the file\nwith open(file_path, 'r', encoding='utf-8') as file:\n    content = file.read()\n# Split the content into paragraphs based on the newline character\nparagraphs = content.split('\\\\x')\n# Remove empty paragraphs\nparagraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup",
		"detail": "posts.gpt_post",
		"documentation": {}
	},
	{
		"label": "paragraphs",
		"kind": 5,
		"importPath": "posts.gpt_post",
		"description": "posts.gpt_post",
		"peekOfCode": "paragraphs = content.split('\\\\x')\n# Remove empty paragraphs\nparagraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup\nllm = OpenAI(model='gpt-3.5-turbo-instruct')\nprompt_template = PromptTemplate.from_template(\n\"\"\"Optimize and compact the paragraph by eliminating inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions and adverbs:\n{text}\"\"\"\n)",
		"detail": "posts.gpt_post",
		"documentation": {}
	},
	{
		"label": "paragraphs",
		"kind": 5,
		"importPath": "posts.gpt_post",
		"description": "posts.gpt_post",
		"peekOfCode": "paragraphs = [paragraph.strip()\n              for paragraph in paragraphs if paragraph.strip()]\n# Your OpenAI setup\nllm = OpenAI(model='gpt-3.5-turbo-instruct')\nprompt_template = PromptTemplate.from_template(\n\"\"\"Optimize and compact the paragraph by eliminating inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions and adverbs:\n{text}\"\"\"\n)\n# prompt_template = PromptTemplate.from_template(\n#     \"\"\"",
		"detail": "posts.gpt_post",
		"documentation": {}
	},
	{
		"label": "llm",
		"kind": 5,
		"importPath": "posts.gpt_post",
		"description": "posts.gpt_post",
		"peekOfCode": "llm = OpenAI(model='gpt-3.5-turbo-instruct')\nprompt_template = PromptTemplate.from_template(\n\"\"\"Optimize and compact the paragraph by eliminating inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions and adverbs:\n{text}\"\"\"\n)\n# prompt_template = PromptTemplate.from_template(\n#     \"\"\"\n#     Remove inappropriate carriage return characters, remove unnecessary words/pronouns/adverbs, and rewrite this content to make this more compact:\n#     {text}\n#     \"\"\"",
		"detail": "posts.gpt_post",
		"documentation": {}
	},
	{
		"label": "prompt_template",
		"kind": 5,
		"importPath": "posts.gpt_post",
		"description": "posts.gpt_post",
		"peekOfCode": "prompt_template = PromptTemplate.from_template(\n\"\"\"Optimize and compact the paragraph by eliminating inappropriate line breaks, unnecessary words, suggestions/invitations/collaborative words, pronouns, conjunctions, prepositions and adverbs:\n{text}\"\"\"\n)\n# prompt_template = PromptTemplate.from_template(\n#     \"\"\"\n#     Remove inappropriate carriage return characters, remove unnecessary words/pronouns/adverbs, and rewrite this content to make this more compact:\n#     {text}\n#     \"\"\"\n# )",
		"detail": "posts.gpt_post",
		"documentation": {}
	},
	{
		"label": "output_parser",
		"kind": 5,
		"importPath": "posts.gpt_post",
		"description": "posts.gpt_post",
		"peekOfCode": "output_parser = StrOutputParser()\n# Iterate over paragraphs and generate summaries\nsummaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI\n    runnable = prompt_template | llm | output_parser\n    summary = runnable.invoke({'text': paragraph})",
		"detail": "posts.gpt_post",
		"documentation": {}
	},
	{
		"label": "summaries",
		"kind": 5,
		"importPath": "posts.gpt_post",
		"description": "posts.gpt_post",
		"peekOfCode": "summaries = []\nfor paragraph in tqdm(paragraphs):\n    # Skip empty paragraphs\n    if not paragraph.strip():\n        continue\n    # Generate summary using OpenAI\n    runnable = prompt_template | llm | output_parser\n    summary = runnable.invoke({'text': paragraph})\n    # Append the summary to the list\n    summaries.append(summary)",
		"detail": "posts.gpt_post",
		"documentation": {}
	},
	{
		"label": "output_file_path",
		"kind": 5,
		"importPath": "posts.gpt_post",
		"description": "posts.gpt_post",
		"peekOfCode": "output_file_path = 'post_summary.txt'\nwith open(output_file_path, 'a', encoding='utf-8') as output_file:\n    for summary in tqdm(summaries):\n        output_file.write(summary + '\\n')\nprint(f'Summaries appended to {output_file_path}')",
		"detail": "posts.gpt_post",
		"documentation": {}
	},
	{
		"label": "set_environment",
		"kind": 2,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "def set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value\n# Initialize environment variables when this module is imported\nset_environment()",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "OPENAI_API_KEY",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "OPENAI_API_KEY = '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'\nHUGGINGFACEHUB_API_TOKEN = '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'\nREPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\nWOLFRAM_ALPHA_APPID = 'U6KWKU-U4L6UKQPXL'\nPROMPTWATCH_API_KEY = \"Wlo5WFgyaFVlMmFMaWsxejZsSnZmMDZSbEhIMjozMWRjZjQ3NC03MGRhLTUxNWMtYTQyNC1iMjExMjQ4YjZkZTg=\"\nLANGCHAIN_TRACING_V2 = \"true\"\nLANGCHAIN_API_KEY = \"ls__b042636c26cf4c6bb4f9d0eb542943d0\"\nTAVILY_API_KEY = \"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\"\nPINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "HUGGINGFACEHUB_API_TOKEN",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "HUGGINGFACEHUB_API_TOKEN = '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'\nREPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\nWOLFRAM_ALPHA_APPID = 'U6KWKU-U4L6UKQPXL'\nPROMPTWATCH_API_KEY = \"Wlo5WFgyaFVlMmFMaWsxejZsSnZmMDZSbEhIMjozMWRjZjQ3NC03MGRhLTUxNWMtYTQyNC1iMjExMjQ4YjZkZTg=\"\nLANGCHAIN_TRACING_V2 = \"true\"\nLANGCHAIN_API_KEY = \"ls__b042636c26cf4c6bb4f9d0eb542943d0\"\nTAVILY_API_KEY = \"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\"\nPINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "REPLICATE_API_TOKEN",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "REPLICATE_API_TOKEN = 'r8_1mJX0C8gULAaN57NPYfhtYEDpEJIgI13zxzoh'\nWOLFRAM_ALPHA_APPID = 'U6KWKU-U4L6UKQPXL'\nPROMPTWATCH_API_KEY = \"Wlo5WFgyaFVlMmFMaWsxejZsSnZmMDZSbEhIMjozMWRjZjQ3NC03MGRhLTUxNWMtYTQyNC1iMjExMjQ4YjZkZTg=\"\nLANGCHAIN_TRACING_V2 = \"true\"\nLANGCHAIN_API_KEY = \"ls__b042636c26cf4c6bb4f9d0eb542943d0\"\nTAVILY_API_KEY = \"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\"\nPINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():\n    variable_dict = globals().items()",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "WOLFRAM_ALPHA_APPID",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "WOLFRAM_ALPHA_APPID = 'U6KWKU-U4L6UKQPXL'\nPROMPTWATCH_API_KEY = \"Wlo5WFgyaFVlMmFMaWsxejZsSnZmMDZSbEhIMjozMWRjZjQ3NC03MGRhLTUxNWMtYTQyNC1iMjExMjQ4YjZkZTg=\"\nLANGCHAIN_TRACING_V2 = \"true\"\nLANGCHAIN_API_KEY = \"ls__b042636c26cf4c6bb4f9d0eb542943d0\"\nTAVILY_API_KEY = \"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\"\nPINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "PROMPTWATCH_API_KEY",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "PROMPTWATCH_API_KEY = \"Wlo5WFgyaFVlMmFMaWsxejZsSnZmMDZSbEhIMjozMWRjZjQ3NC03MGRhLTUxNWMtYTQyNC1iMjExMjQ4YjZkZTg=\"\nLANGCHAIN_TRACING_V2 = \"true\"\nLANGCHAIN_API_KEY = \"ls__b042636c26cf4c6bb4f9d0eb542943d0\"\nTAVILY_API_KEY = \"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\"\nPINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "LANGCHAIN_TRACING_V2",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "LANGCHAIN_TRACING_V2 = \"true\"\nLANGCHAIN_API_KEY = \"ls__b042636c26cf4c6bb4f9d0eb542943d0\"\nTAVILY_API_KEY = \"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\"\nPINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "LANGCHAIN_API_KEY",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "LANGCHAIN_API_KEY = \"ls__b042636c26cf4c6bb4f9d0eb542943d0\"\nTAVILY_API_KEY = \"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\"\nPINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value\n# Initialize environment variables when this module is imported",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "TAVILY_API_KEY",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "TAVILY_API_KEY = \"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\"\nPINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value\n# Initialize environment variables when this module is imported\nset_environment()",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "PINECONE_API_KEY",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "PINECONE_API_KEY = \"4c183128-9d40-4846-9620-30f636051544\"\nPINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value\n# Initialize environment variables when this module is imported\nset_environment()",
		"detail": "config",
		"documentation": {}
	},
	{
		"label": "PINECONE_ENVIRONMENT",
		"kind": 5,
		"importPath": "config",
		"description": "config",
		"peekOfCode": "PINECONE_ENVIRONMENT = \"gcp-starter\"\ndef set_environment():\n    variable_dict = globals().items()\n    for key, value in variable_dict:\n        if \"API\" in key or \"ID\" in key:\n            os.environ[key] = value\n# Initialize environment variables when this module is imported\nset_environment()",
		"detail": "config",
		"documentation": {}
	}
]
